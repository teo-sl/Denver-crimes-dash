{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.appName(\"Stars\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('crime.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- incident_id: long (nullable = true)\n",
      " |-- offense_id: long (nullable = true)\n",
      " |-- OFFENSE_CODE: integer (nullable = true)\n",
      " |-- OFFENSE_CODE_EXTENSION: integer (nullable = true)\n",
      " |-- OFFENSE_TYPE_ID: string (nullable = true)\n",
      " |-- OFFENSE_CATEGORY_ID: string (nullable = true)\n",
      " |-- FIRST_OCCURRENCE_DATE: string (nullable = true)\n",
      " |-- LAST_OCCURRENCE_DATE: string (nullable = true)\n",
      " |-- REPORTED_DATE: string (nullable = true)\n",
      " |-- INCIDENT_ADDRESS: string (nullable = true)\n",
      " |-- GEO_X: double (nullable = true)\n",
      " |-- GEO_Y: double (nullable = true)\n",
      " |-- GEO_LON: double (nullable = true)\n",
      " |-- GEO_LAT: double (nullable = true)\n",
      " |-- DISTRICT_ID: string (nullable = true)\n",
      " |-- PRECINCT_ID: integer (nullable = true)\n",
      " |-- NEIGHBORHOOD_ID: string (nullable = true)\n",
      " |-- IS_CRIME: integer (nullable = true)\n",
      " |-- IS_TRAFFIC: integer (nullable = true)\n",
      " |-- VICTIM_COUNT: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399572"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of rows in the dataframe\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------------+----------------------+---------------+-------------------+---------------------+--------------------+-------------+----------------+-----+-----+-------+-------+-----------+-----------+---------------+--------+----------+------------+\n",
      "|incident_id|offense_id|OFFENSE_CODE|OFFENSE_CODE_EXTENSION|OFFENSE_TYPE_ID|OFFENSE_CATEGORY_ID|FIRST_OCCURRENCE_DATE|LAST_OCCURRENCE_DATE|REPORTED_DATE|INCIDENT_ADDRESS|GEO_X|GEO_Y|GEO_LON|GEO_LAT|DISTRICT_ID|PRECINCT_ID|NEIGHBORHOOD_ID|IS_CRIME|IS_TRAFFIC|VICTIM_COUNT|\n",
      "+-----------+----------+------------+----------------------+---------------+-------------------+---------------------+--------------------+-------------+----------------+-----+-----+-------+-------+-----------+-----------+---------------+--------+----------+------------+\n",
      "|          0|         0|           0|                     0|              0|                  0|                    0|              194340|            0|            5560| 5560| 5560|   5560|   5560|       1461|          0|           5330|       0|         0|           0|\n",
      "+-----------+----------+------------+----------------------+---------------+-------------------+---------------------+--------------------+-------------+----------------+-----+-----+-------+-------+-----------+-----------+---------------+--------+----------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# the percantege of missing values in each column\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop a column\n",
    "df = df.drop('LAST_OCCURRENCE_DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OFFENSE_CODE',\n",
       " 'OFFENSE_CODE_EXTENSION',\n",
       " 'GEO_X',\n",
       " 'GEO_Y',\n",
       " 'GEO_LON',\n",
       " 'GEO_LAT',\n",
       " 'PRECINCT_ID',\n",
       " 'IS_CRIME',\n",
       " 'IS_TRAFFIC',\n",
       " 'VICTIM_COUNT']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all numeric type columns\n",
    "numeric_columns = [t[0] for t in df.dtypes if t[1] in ['int', 'double','long','float','integer']]\n",
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the missing values with the mean of the column using imputer\n",
    "from pyspark.ml.feature import Imputer\n",
    "imputer = Imputer(inputCols=numeric_columns, outputCols=numeric_columns,strategy='mean')\n",
    "df = imputer.fit(df).transform(df)\n",
    "\n",
    "\n",
    "# fill neighborhood_id with the most frequent value\n",
    "from pyspark.sql.functions import col, when\n",
    "df = df.withColumn('NEIGHBORHOOD_ID', when(col('NEIGHBORHOOD_ID').isNull(), 1).otherwise(col('NEIGHBORHOOD_ID')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"INCIDENT_ADDRESS\",\"DISTRICT_ID\",\n",
    "        \"incident_id\",\"offense_id\",\"OFFENSE_CODE\",\n",
    "        \"OFFENSE_CODE_EXTENSION\",\"PRECINCT_ID\",\"DISTRICT_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+---------------------+-------------+-----+-----+-------+-------+---------------+--------+----------+------------+\n",
      "|OFFENSE_TYPE_ID|OFFENSE_CATEGORY_ID|FIRST_OCCURRENCE_DATE|REPORTED_DATE|GEO_X|GEO_Y|GEO_LON|GEO_LAT|NEIGHBORHOOD_ID|IS_CRIME|IS_TRAFFIC|VICTIM_COUNT|\n",
      "+---------------+-------------------+---------------------+-------------+-----+-----+-------+-------+---------------+--------+----------+------------+\n",
      "|              0|                  0|                    0|            0|    0|    0|      0|      0|              0|       0|         0|           0|\n",
      "+---------------+-------------------+---------------------+-------------+-----+-----+-------+-------+---------------+--------+----------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "# convert FIRST_OCCURRENCE_DATE to a timestamp in format MM/dd/yyyy hh:mm:ss a\n",
    "df = df.withColumn(\"FIRST_OCCURRENCE_DATE\", to_timestamp(\"FIRST_OCCURRENCE_DATE\", \"MM/dd/yyyy hh:mm:ss a\"))\n",
    "df = df.withColumn(\"REPORTED_DATE\", to_timestamp(\"REPORTED_DATE\", \"MM/dd/yyyy hh:mm:ss a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- OFFENSE_TYPE_ID: string (nullable = true)\n",
      " |-- OFFENSE_CATEGORY_ID: string (nullable = true)\n",
      " |-- FIRST_OCCURRENCE_DATE: timestamp (nullable = true)\n",
      " |-- REPORTED_DATE: timestamp (nullable = true)\n",
      " |-- GEO_X: double (nullable = true)\n",
      " |-- GEO_Y: double (nullable = true)\n",
      " |-- GEO_LON: double (nullable = true)\n",
      " |-- GEO_LAT: double (nullable = true)\n",
      " |-- NEIGHBORHOOD_ID: string (nullable = true)\n",
      " |-- IS_CRIME: integer (nullable = true)\n",
      " |-- IS_TRAFFIC: integer (nullable = true)\n",
      " |-- VICTIM_COUNT: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save the dataframe on a single repartitioned file\n",
    "df.repartition(1).write.csv('crime_clean.csv', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
